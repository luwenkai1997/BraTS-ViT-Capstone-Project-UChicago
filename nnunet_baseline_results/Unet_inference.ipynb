{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO4AkdGWbwlBHh6cPMaVp7e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ANGV-WL1hiG","executionInfo":{"status":"ok","timestamp":1747851189131,"user_tz":-480,"elapsed":197538,"user":{"displayName":"Silin","userId":"01581346555860269201"}},"outputId":"d9786ca5-83df-42d8-9bb5-1dcc3e3b8cfc"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.1/184.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m119.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip uninstall -y torch torchvision torchaudio -qq\n","!pip install -q torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121\n","!pip install -q nnunetv2==2.4.2 monai nibabel"]},{"cell_type":"code","source":["!pip install -q nibabel matplotlib pandas"],"metadata":{"id":"1Ah6GwSo2Pn7","executionInfo":{"status":"ok","timestamp":1747851341809,"user_tz":-480,"elapsed":1910,"user":{"displayName":"Silin","userId":"01581346555860269201"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 重新安装依赖，但锁定 numpy 版本\n","# ---- Step ① 已手动点过 Runtime ▸ Restart runtime() ----\n","\n","# Step ②: 安装统一依赖\n","!pip install -q --upgrade \"numpy>=1.26,<2\" nibabel pandas matplotlib scikit-image\n","\n","# Step ③: 执行前 5 病例推理 + 评估 + 可视化\n","# （把之前给你的整段脚本粘在这行下面即可）\n","\n","import json, shutil, subprocess, textwrap, re, os, nibabel as nib\n","import numpy as np, pandas as pd, matplotlib.pyplot as plt\n","from pathlib import Path\n","from IPython.display import display, Image, Markdown\n","from google.colab import drive\n","\n","# ---------- 0. 常量 ----------\n","N_CASES      = 5                    # 取前 N 个病例\n","MODALITY     = \"t1c\"                # 叠加底图，可改 t1n/t2f/t2w\n","DRIVE_ROOT   = Path(\"/content/drive/MyDrive/data\")\n","TRAIN_DIR    = DRIVE_ROOT / \"training_data\"\n","PRED_DIR     = DRIVE_ROOT / \"output\"          # 预测和 PNG 保存处\n","PRED_DIR.mkdir(exist_ok=True)\n","\n","# 挂载 Google Drive\n","drive.mount(\"/content/drive\", force_remount=False)\n","\n","# ---------- 1. 选前 N 个病例 ----------\n","cases = sorted([p.name for p in TRAIN_DIR.iterdir() if p.is_dir()])[:N_CASES]\n","assert cases, \"❌ training_data 为空！\"\n","print(\"将处理病例:\", cases)\n","\n","# ---------- 2. 准备 nnUNet 测试集目录 ----------\n","plans = json.load((DRIVE_ROOT/\"plans.json\").open())\n","DATASET  = plans[\"dataset_name\"]\n","RAW_IMG  = Path(\"/content/nnUNet_raw\") / DATASET / \"imagesTs\"\n","RAW_IMG.mkdir(parents=True, exist_ok=True)\n","\n","MOD_MAP = {\"t1c\":\"0000\",\"t1n\":\"0001\",\"t2f\":\"0002\",\"t2w\":\"0003\"}\n","for case in cases:\n","    case_dir = TRAIN_DIR / case\n","    for mod, idx in MOD_MAP.items():\n","        src = case_dir / f\"{case}-{mod}.nii.gz\"\n","        dst = RAW_IMG  / f\"{case}_{idx}.nii.gz\"\n","        dst.unlink(missing_ok=True)\n","        dst.symlink_to(src.resolve())\n","print(\"✅ 已软链影像 →\", RAW_IMG)\n","\n","# ---------- 3. 运行推理 ----------\n","device = \"cuda\" if Path(\"/usr/bin/nvidia-smi\").exists() else \"cpu\"\n","cmd = textwrap.dedent(f\"\"\"\n","    nnUNetv2_predict \\\n","      -i {RAW_IMG} \\\n","      -o /content/pred \\\n","      -d {DATASET} \\\n","      -c 3d_fullres \\\n","      -f 0 \\\n","      -device {device} \\\n","      --disable_tta\n","\"\"\")\n","print(\"🚀 推理命令:\\n\", cmd)\n","subprocess.run(cmd, shell=True, check=True)\n","\n","# 把预测复制到 Drive/output\n","for p in Path(\"/content/pred\").glob(\"*.nii*\"):\n","    shutil.copy(p, PRED_DIR / p.name)\n","print(\"✅ 推理结果已保存 →\", PRED_DIR)\n","\n","# ---------- 4. 评估 & 可视化 ----------\n","metrics, pngs = [], []\n","for case in cases:\n","    pred_fp = PRED_DIR / f\"{case}.nii.gz\"\n","    gt_fp   = TRAIN_DIR / case / f\"{case}-seg.nii.gz\"\n","    img_fp  = TRAIN_DIR / case / f\"{case}-{MODALITY}.nii.gz\"\n","    assert pred_fp.exists() and gt_fp.exists() and img_fp.exists(), f\"缺文件: {case}\"\n","\n","    pred = nib.load(pred_fp).get_fdata() > 0\n","    gt   = nib.load(gt_fp).get_fdata() > 0\n","    img  = nib.load(img_fp).get_fdata()\n","\n","    tp = np.logical_and(pred, gt).sum()\n","    fp = np.logical_and(pred, ~gt).sum()\n","    fn = np.logical_and(~pred, gt).sum()\n","    dice = 2*tp / (2*tp + fp + fn + 1e-8)\n","    iou  = tp / (tp + fp + fn + 1e-8)\n","    metrics.append({\"case\": case, \"dice\": dice, \"iou\": iou})\n","\n","    # 中央轴向切片\n","    z = img.shape[2]//2\n","    norm = lambda x: (x - x.min())/(x.ptp()+1e-8)\n","    img_sl, pred_sl, gt_sl = img[...,z], pred[...,z], gt[...,z]\n","\n","    fig, ax = plt.subplots(1,3, figsize=(12,4))\n","    ax[0].imshow(norm(img_sl).T, cmap='gray', origin='lower')\n","    ax[0].imshow(pred_sl.T, cmap='Reds', alpha=.35, origin='lower')\n","    ax[0].set_title(\"Prediction\"); ax[0].axis('off')\n","\n","    ax[1].imshow(norm(img_sl).T, cmap='gray', origin='lower')\n","    ax[1].imshow(gt_sl.T, cmap='Reds', alpha=.35, origin='lower')\n","    ax[1].set_title(\"Ground-Truth\"); ax[1].axis('off')\n","\n","    overlay = np.zeros((*pred_sl.T.shape,4))\n","    overlay[pred_sl.T] = [1,0,0,.35]\n","    overlay[np.logical_and(gt_sl.T, ~pred_sl.T)] = [0,0,1,.35]\n","    ax[2].imshow(norm(img_sl).T, cmap='gray', origin='lower')\n","    ax[2].imshow(overlay, origin='lower')\n","    ax[2].set_title(\"Overlap\"); ax[2].axis('off')\n","\n","    fig.suptitle(f\"{case}  Dice={dice:.3f}  IoU={iou:.3f}\")\n","    png_path = PRED_DIR / f\"{case}_compare.png\"\n","    fig.savefig(png_path, dpi=150, bbox_inches='tight'); plt.close(fig)\n","    pngs.append(png_path)\n","    print(\"📷 保存 →\", png_path)\n","\n","# ---------- 5. 保存 & 展示指标 ----------\n","metrics_path = PRED_DIR / \"metrics_summary.json\"\n","metrics_path.write_text(json.dumps(metrics, indent=2))\n","print(\"✅ 指标写入\", metrics_path)\n","\n","df = pd.DataFrame(metrics).sort_values(\"dice\", ascending=False)\n","display(Markdown(\"## Segmentation Metrics\")); display(df)\n","\n","display(Markdown(\"### Overlay comparisons\"))\n","for p in pngs:\n","    display(Image(filename=str(p)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":593},"id":"PuGDmdkT2Zs8","executionInfo":{"status":"error","timestamp":1747262908870,"user_tz":-480,"elapsed":57840,"user":{"displayName":"Silin","userId":"01581346555860269201"}},"outputId":"b8df9143-8ba8-413c-def8-d23a6d5d084f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","将处理病例: ['BraTS-GLI-02405-100', 'BraTS-GLI-02405-101', 'BraTS-GLI-02406-100', 'BraTS-GLI-02407-100', 'BraTS-GLI-02408-100']\n","✅ 已软链影像 → /content/nnUNet_raw/Dataset241_BraTS_2024_Real/imagesTs\n","🚀 推理命令:\n"," \n","nnUNetv2_predict       -i /content/nnUNet_raw/Dataset241_BraTS_2024_Real/imagesTs       -o /content/pred       -d Dataset241_BraTS_2024_Real       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n","\n"]},{"output_type":"error","ename":"CalledProcessError","evalue":"Command '\nnnUNetv2_predict       -i /content/nnUNet_raw/Dataset241_BraTS_2024_Real/imagesTs       -o /content/pred       -d Dataset241_BraTS_2024_Real       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n' returned non-zero exit status 1.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-47fe4278a568>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \"\"\")\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🚀 推理命令:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# 把预测复制到 Drive/output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCalledProcessError\u001b[0m: Command '\nnnUNetv2_predict       -i /content/nnUNet_raw/Dataset241_BraTS_2024_Real/imagesTs       -o /content/pred       -d Dataset241_BraTS_2024_Real       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n' returned non-zero exit status 1."]}]},{"cell_type":"code","source":["import subprocess, textwrap, pathlib, os, json, re, shutil\n","from IPython.display import Markdown\n","\n","cmd = textwrap.dedent(\"\"\"\n","    nnUNetv2_predict \\\n","      -i /content/nnUNet_raw/Dataset241_BraTS_2024_Real/imagesTs \\\n","      -o /content/pred \\\n","      -d Dataset241_BraTS_2024_Real \\\n","      -c 3d_fullres \\\n","      -f 0 \\\n","      -device cpu \\\n","      --disable_tta\n","\"\"\")\n","\n","res = subprocess.run(cmd, shell=True, text=True,\n","                     capture_output=True)\n","print(\"---- STDOUT ----\\n\", res.stdout)\n","print(\"---- STDERR ----\\n\", res.stderr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qNaJCpFvALZs","executionInfo":{"status":"ok","timestamp":1747263216966,"user_tz":-480,"elapsed":6901,"user":{"displayName":"Silin","userId":"01581346555860269201"}},"outputId":"d102b889-626b-4006-a1c4-e6599af46ec5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---- STDOUT ----\n"," nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n","nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n","nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n","\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","\n","---- STDERR ----\n"," Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_predict\", line 8, in <module>\n","    sys.exit(predict_entry_point())\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/inference/predict_from_raw_data.py\", line 828, in predict_entry_point\n","    model_folder = get_output_folder(args.d, args.tr, args.p, args.c)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/utilities/file_path_utilities.py\", line 22, in get_output_folder\n","    tmp = join(nnUNet_results, maybe_convert_to_dataset_name(dataset_name_or_id),\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<frozen posixpath>\", line 76, in join\n","TypeError: expected str, bytes or os.PathLike object, not NoneType\n","\n"]}]},{"cell_type":"code","source":[" # ======================== nnUNetv2 一键推理 =========================\n","# 放在 Colab 单元格直接运行。Google Drive 中 data/ 目录需包含：\n","#  ├─ plans.json\n","#  ├─ dataset.json               ← 可以是 v1 或 v2 格式，脚本会自动修\n","#  ├─ checkpoint_final.pth       ← 训练好的权重\n","#  ├─ BraTS-****-t1c.nii.gz …    ← 四通道影像文件\n","#  └─ output/                    ← 推理结果将复制到这里（若无会创建）\n","# ===================================================================\n","\n","import json, shutil, subprocess, textwrap, re, os\n","from pathlib import Path\n","from google.colab import drive\n","\n","# ---------- 0. 挂载 Google Drive ----------\n","drive.mount(\"/content/drive\", force_remount=False)\n","DRIVE = Path(\"/content/drive/MyDrive/data\").resolve()\n","\n","# ---------- 1. 解析 plans.json ----------\n","plans_path = DRIVE / \"plans.json\"\n","assert plans_path.exists(), \"❌ plans.json 不存在于 Drive/data！\"\n","DATASET = json.load(plans_path.open())[\"dataset_name\"]\n","print(\"📌 数据集名:\", DATASET)\n","\n","# ---------- 2. 目录准备 ----------\n","RAW_DIR   = Path(\"/content/nnUNet_raw\") / DATASET\n","RAW_IMG   = RAW_DIR / \"imagesTs\"\n","RES_DIR   = Path(\"/content/nnUNet_results\") / DATASET / \"nnUNetTrainer__nnUNetPlans__3d_fullres\"\n","RAW_IMG.mkdir(parents=True, exist_ok=True)\n","RES_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# ---------- 3. 软链影像文件 ----------\n","MOD_MAP = {\"t1c\": \"0000\", \"t1n\": \"0001\", \"t2f\": \"0002\", \"t2w\": \"0003\"}\n","for img in DRIVE.glob(\"*.nii*\"):\n","    m = re.match(r\"(.+)-([a-z0-9]{3})(?:\\.nii(\\.gz)?)$\", img.name)\n","    if m and m.group(2) in MOD_MAP:\n","        link = RAW_IMG / f\"{m.group(1)}_{MOD_MAP[m.group(2)]}.nii.gz\"\n","        link.unlink(missing_ok=True)\n","        link.symlink_to(img.resolve())\n","print(\"✅ 已软链影像 →\", RAW_IMG)\n","\n","# ---------- 4. 同步 & 修正 dataset.json ----------\n","LABELS_FIXED = {          # !!! 根据权重输出通道数修改 !!!\n","    \"background\": 0,\n","    \"whole_tumor\": 1,\n","    \"tumor_core\": 2,\n","    \"enhancing\": 3\n","}\n","\n","ds_src = DRIVE / \"dataset.json\"\n","assert ds_src.exists(), \"❌ dataset.json 不存在于 Drive/data！\"\n","ds_dst = RAW_DIR / \"dataset.json\"\n","shutil.copy(ds_src, ds_dst)\n","\n","# 自动把 v1 风格 (数字→名字) 反转为 v2 风格 (名字→数字)\n","with ds_dst.open() as f:\n","    ds = json.load(f)\n","if \"background\" not in ds[\"labels\"]:\n","    ds[\"labels\"] = {v: int(k) for k, v in ds[\"labels\"].items()}\n","\n","# 覆盖为固定标签（确保通道数匹配）\n","ds[\"labels\"] = LABELS_FIXED\n","with ds_dst.open(\"w\") as f:\n","    json.dump(ds, f, indent=2)\n","shutil.copy(ds_dst, RES_DIR / \"dataset.json\")\n","print(\"✅ dataset.json 已修正并同步\")\n","\n","# ---------- 5. 复制 plans.json & 权重 ----------\n","shutil.copy(plans_path, RES_DIR / \"plans.json\")\n","(RES_DIR / \"fold_0\").mkdir(exist_ok=True)\n","shutil.copy(DRIVE / \"checkpoint_final.pth\",\n","            RES_DIR / \"fold_0/checkpoint_final.pth\")\n","\n","# ---------- 6. 设备选择 ----------\n","device = \"cuda\" if Path(\"/usr/bin/nvidia-smi\").exists() else \"cpu\"\n","print(\"📌 推理设备:\", device.upper())\n","\n","# ---------- 7. 执行推理 ----------\n","OUT_DIR = Path(\"/content/pred\")\n","cmd = textwrap.dedent(f\"\"\"\n","    nnUNetv2_predict \\\n","      -i {RAW_IMG} \\\n","      -o {OUT_DIR} \\\n","      -d {DATASET} \\\n","      -c 3d_fullres \\\n","      -f 0 \\\n","      -device {device} \\\n","      --disable_tta\n","\"\"\")\n","print(\"🚀 运行命令:\\n\", cmd)\n","subprocess.run(cmd, shell=True, check=True)\n","print(\"✅ 推理完成！结果在\", OUT_DIR)\n","\n","# ---------- 8. 结果复制回 Drive ----------\n","( DRIVE / \"output\").mkdir(exist_ok=True)\n","for p in OUT_DIR.glob(\"*.nii*\"):\n","    shutil.copy(p, DRIVE / \"output\" / p.name)\n","print(f\"✅ 已复制 {len(list(OUT_DIR.glob('*.nii*')))} 个文件 → {DRIVE/'output'}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":523},"id":"KFS6FbVn2d_o","executionInfo":{"status":"error","timestamp":1747261094666,"user_tz":-480,"elapsed":45560,"user":{"displayName":"Silin","userId":"01581346555860269201"}},"outputId":"0e9f55e4-47b3-4e63-d61c-3ac5d9b7d7a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","📌 数据集名: Dataset241_BraTS_2024_Real\n","✅ 已软链影像 → /content/nnUNet_raw/Dataset241_BraTS_2024_Real/imagesTs\n","✅ dataset.json 已修正并同步\n","📌 推理设备: CPU\n","🚀 运行命令:\n"," \n","nnUNetv2_predict       -i /content/nnUNet_raw/Dataset241_BraTS_2024_Real/imagesTs       -o /content/pred       -d Dataset241_BraTS_2024_Real       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n","\n"]},{"output_type":"error","ename":"CalledProcessError","evalue":"Command '\nnnUNetv2_predict       -i /content/nnUNet_raw/Dataset241_BraTS_2024_Real/imagesTs       -o /content/pred       -d Dataset241_BraTS_2024_Real       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n' returned non-zero exit status 1.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-29e3124b2f2b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \"\"\")\n\u001b[1;32m     89\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🚀 运行命令:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ 推理完成！结果在\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCalledProcessError\u001b[0m: Command '\nnnUNetv2_predict       -i /content/nnUNet_raw/Dataset241_BraTS_2024_Real/imagesTs       -o /content/pred       -d Dataset241_BraTS_2024_Real       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n' returned non-zero exit status 1."]}]},{"cell_type":"code","source":["!pip install -q --upgrade --force-reinstall numpy pandas==2.2.2 matplotlib nibabel\n","!pip uninstall -y torch torchvision torchaudio -qq\n","!pip install -q torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121\n","!pip install -q nnunetv2==2.4.2 monai nibabel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGkDGVypEjAM","executionInfo":{"status":"ok","timestamp":1747854496546,"user_tz":-480,"elapsed":306609,"user":{"displayName":"Silin","userId":"01581346555860269201"}},"outputId":"23178ed6-dfc4-4449-f7ba-bd4a79a16119"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.5/104.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n","langchain-core 0.3.59 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.1/184.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["\n","#  ├─ /content/drive/MyDrive/data/\n","#       ├─ plans.json\n","#       ├─ dataset.json\n","#       ├─ checkpoint_final.pth\n","#       ├─ training_data/\n","#           ├─ CaseA/CaseA-t1c.nii.gz … CaseA-seg.nii.gz\n","#           ├─ CaseB/…\n","#       ├─ output/\n","\n","\n","# 安装依赖\n","!pip install -q nibabel matplotlib pandas\n","\n","import os\n","import json\n","import shutil\n","import subprocess\n","import textwrap\n","import re\n","from pathlib import Path\n","\n","import nibabel as nib\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from IPython.display import display, Image, Markdown\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=False)\n","# ---------- 0. 常量 & 挂载 Drive ----------\n","N_CASES    = 5\n","MODALITY   = \"t1c\"   # 如果要用 t1n、t2f、t2w，请改这里\n","DRIVE_ROOT = Path(\"/content/drive/MyDrive/data\")\n","TRAIN_DIR  = DRIVE_ROOT / \"training_data\"\n","OUTPUT_DIR = DRIVE_ROOT / \"output\"\n","OUTPUT_DIR.mkdir(exist_ok=True)\n","\n","\n","\n","# ---------- 1. 解析 plans.json & 设置 nnUNet 环境变量 ----------\n","plans = json.load((DRIVE_ROOT/\"plans.json\").open())\n","DATASET = plans[\"dataset_name\"]\n","\n","# 确保 nnUNet v2 能找到目录\n","for d in (\"/content/nnUNet_raw\", \"/content/nnUNet_preprocessed\", \"/content/nnUNet_results\"):\n","    Path(d).mkdir(parents=True, exist_ok=True)\n","os.environ.update({\n","    \"nnUNet_raw\": \"/content/nnUNet_raw\",\n","    \"nnUNet_preprocessed\": \"/content/nnUNet_preprocessed\",\n","    \"nnUNet_results\": \"/content/nnUNet_results\",\n","    \"RESULTS_FOLDER\": \"/content/nnUNet_results\"\n","})\n","\n","# ---------- 2. 选前 N_CASES 病例 & 软链影像到 nnUNet_raw ----------\n","cases = sorted([p.name for p in TRAIN_DIR.iterdir() if p.is_dir()])[:N_CASES]\n","assert cases, \"training_data 目录中没有病例文件夹！\"\n","print(\"处理病例:\", cases)\n","\n","IMG_TS = Path(\"/content/nnUNet_raw\")/DATASET/\"imagesTs\"\n","IMG_TS.mkdir(parents=True, exist_ok=True)\n","MOD_MAP = {\"t1c\":\"0000\",\"t1n\":\"0001\",\"t2f\":\"0002\",\"t2w\":\"0003\"}\n","\n","for case in cases:\n","    src_dir = TRAIN_DIR/case\n","    for mod, idx in MOD_MAP.items():\n","        src = src_dir/f\"{case}-{mod}.nii.gz\"\n","        dst = IMG_TS/f\"{case}_{idx}.nii.gz\"\n","        dst.unlink(missing_ok=True)\n","        dst.symlink_to(src.resolve())\n","\n","print(\"✅ 已软链前五病例影像至\", IMG_TS)\n","\n","# ---------- 3. 执行 nnUNetv2_predict ----------\n","device = \"cuda\" if Path(\"/usr/bin/nvidia-smi\").exists() else \"cpu\"\n","cmd = textwrap.dedent(f\"\"\"\n","    nnUNetv2_predict \\\n","      -i {IMG_TS} \\\n","      -o /content/pred \\\n","      -d {DATASET} \\\n","      -c 3d_fullres \\\n","      -f 0 \\\n","      -device {device} \\\n","      --disable_tta\n","\"\"\")\n","print(\"🚀 运行命令：\", cmd)\n","subprocess.run(cmd, shell=True, check=True)\n","print(\"✅ 推理完成 → /content/pred\")\n","\n","# 复制预测结果到 Drive/output\n","for p in Path(\"/content/pred\").glob(\"*.nii*\"):\n","    shutil.copy(p, OUTPUT_DIR/p.name)\n","print(\"✅ 预测结果已复制到\", OUTPUT_DIR)\n","\n","# ---------- 4. 评估 & 可视化 ----------\n","metrics = []\n","png_paths = []\n","\n","for case in cases:\n","    pred_fp = OUTPUT_DIR/f\"{case}.nii.gz\"\n","    gt_fp   = TRAIN_DIR/case/f\"{case}-seg.nii.gz\"\n","    img_fp  = TRAIN_DIR/case/f\"{case}-{MODALITY}.nii.gz\"\n","    assert pred_fp.exists() and gt_fp.exists() and img_fp.exists(), f\"{case} 文件不完整\"\n","\n","    pred = nib.load(pred_fp).get_fdata() > 0\n","    gt   = nib.load(gt_fp).get_fdata() > 0\n","    img  = nib.load(img_fp).get_fdata()\n","\n","    tp = np.logical_and(pred, gt).sum()\n","    fp = np.logical_and(pred, ~gt).sum()\n","    fn = np.logical_and(~pred, gt).sum()\n","    dice = 2*tp / (2*tp + fp + fn + 1e-8)\n","    iou  = tp / (tp + fp + fn + 1e-8)\n","    metrics.append({\"case\": case, \"dice\": float(dice), \"iou\": float(iou)})\n","\n","    # 中央轴向切片可视化\n","    z = img.shape[2]//2\n","    img_sl, pred_sl, gt_sl = img[:,:,z], pred[:,:,z], gt[:,:,z]\n","    norm = lambda x: (x - x.min())/(x.ptp()+1e-8)\n","\n","    fig, ax = plt.subplots(1,3, figsize=(12,4))\n","    ax[0].imshow(norm(img_sl).T, cmap='gray', origin='lower')\n","    ax[0].imshow(pred_sl.T, cmap='Reds', alpha=.35, origin='lower')\n","    ax[0].set_title(\"Prediction\"); ax[0].axis('off')\n","\n","    ax[1].imshow(norm(img_sl).T, cmap='gray', origin='lower')\n","    ax[1].imshow(gt_sl.T, cmap='Reds', alpha=.35, origin='lower')\n","    ax[1].set_title(\"Ground-Truth\"); ax[1].axis('off')\n","\n","    overlay = np.zeros((*pred_sl.T.shape,4))\n","    overlay[pred_sl.T] = [1,0,0,.35]\n","    overlay[np.logical_and(gt_sl.T, ~pred_sl.T)] = [0,0,1,.35]\n","    ax[2].imshow(norm(img_sl).T, cmap='gray', origin='lower')\n","    ax[2].imshow(overlay, origin='lower')\n","    ax[2].set_title(\"Overlap\"); ax[2].axis('off')\n","\n","    fig.suptitle(f\"{case}  Dice={dice:.3f}  IoU={iou:.3f}\")\n","    png_fp = OUTPUT_DIR/f\"{case}_compare.png\"\n","    fig.savefig(png_fp, dpi=150, bbox_inches='tight')\n","    plt.close(fig)\n","    png_paths.append(png_fp)\n","    print(\"📷 保存对比图 →\", png_fp)\n","\n","# ---------- 5. 保存指标 & 展示 ----------\n","metrics_fp = OUTPUT_DIR/\"metrics_summary.json\"\n","metrics_fp.write_text(json.dumps(metrics, indent=2))\n","print(\"✅ 指标保存 →\", metrics_fp)\n","\n","# 在 Notebook 中展示\n","df = pd.DataFrame(metrics).sort_values(\"dice\", ascending=False)\n","display(Markdown(\"## Segmentation Metrics\"))\n","display(df)\n","\n","display(Markdown(\"### Overlay Comparisons\"))\n","for p in png_paths:\n","    display(Image(str(p)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":508},"id":"li1OEMYN38i-","executionInfo":{"status":"error","timestamp":1747854903871,"user_tz":-480,"elapsed":46747,"user":{"displayName":"Silin","userId":"01581346555860269201"}},"outputId":"a1076f27-a5ab-4dd3-bf80-fa68b063c201"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","处理病例: ['BraTS-GLI-00000-000', 'BraTS-GLI-00002-000', 'BraTS-GLI-00003-000', 'BraTS-GLI-00005-000', 'BraTS-GLI-00006-000']\n","✅ 已软链前五病例影像至 /content/nnUNet_raw/Dataset232_BraTS_2023_rGANs/imagesTs\n","🚀 运行命令： \n","nnUNetv2_predict       -i /content/nnUNet_raw/Dataset232_BraTS_2023_rGANs/imagesTs       -o /content/pred       -d Dataset232_BraTS_2023_rGANs       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n","\n"]},{"output_type":"error","ename":"CalledProcessError","evalue":"Command '\nnnUNetv2_predict       -i /content/nnUNet_raw/Dataset232_BraTS_2023_rGANs/imagesTs       -o /content/pred       -d Dataset232_BraTS_2023_rGANs       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n' returned non-zero exit status 1.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-746b5db624eb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \"\"\")\n\u001b[1;32m     84\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🚀 运行命令：\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ 推理完成 → /content/pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCalledProcessError\u001b[0m: Command '\nnnUNetv2_predict       -i /content/nnUNet_raw/Dataset232_BraTS_2023_rGANs/imagesTs       -o /content/pred       -d Dataset232_BraTS_2023_rGANs       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n' returned non-zero exit status 1."]}]},{"cell_type":"code","source":["# 2. 导入 & 挂载 Drive\n","import os, shutil, subprocess, textwrap\n","from pathlib import Path\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=False)\n","\n","# 3. 环境变量配置\n","os.environ.update({\n","    \"nnUNet_raw\": \"/content/nnUNet_raw\",\n","    \"nnUNet_preprocessed\": \"/content/nnUNet_preprocessed\",\n","    \"nnUNet_results\": \"/content/nnUNet_results\",\n","    \"RESULTS_FOLDER\": \"/content/nnUNet_results\"\n","})\n","\n","# 4. 路径设定\n","DRIVE_ROOT = Path(\"/content/drive/MyDrive/data\")\n","DATASET    = \"Dataset232_BraTS_2023_rGANs\"   # 请和你的 plans.json 中 dataset_name 保持一致\n","\n","# 5. 准备 nnUNet_raw：软链前处理原始影像\n","RAW_TS = Path(os.environ[\"nnUNet_raw\"]) / DATASET / \"imagesTs\"\n","RAW_TS.mkdir(parents=True, exist_ok=True)\n","\n","MOD_MAP = {\"t1c\":\"0000\",\"t1n\":\"0001\",\"t2f\":\"0002\",\"t2w\":\"0003\"}\n","for case_dir in (DRIVE_ROOT/\"training_data\").iterdir():\n","    case = case_dir.name\n","    for mod, idx in MOD_MAP.items():\n","        src = case_dir / f\"{case}-{mod}.nii.gz\"\n","        dst = RAW_TS   / f\"{case}_{idx}.nii.gz\"\n","        dst.unlink(missing_ok=True)\n","        dst.symlink_to(src.resolve())\n","print(\"✅ 已软链原始影像 →\", RAW_TS)\n","\n","# 6. 准备 nnUNet_preprocessed：拷贝 dataset.json、plans.json 及 fold_* 目录\n","PREPROC_DST = Path(os.environ[\"nnUNet_preprocessed\"]) / DATASET\n","PREPROC_DST.mkdir(parents=True, exist_ok=True)\n","for fn in [\"dataset.json\",\"plans.json\"]:\n","    shutil.copy(DRIVE_ROOT/fn, PREPROC_DST/fn)\n","for fold in DRIVE_ROOT.glob(\"fold_*\"):\n","    if fold.is_dir():\n","        shutil.copytree(fold, PREPROC_DST/fold.name, dirs_exist_ok=True)\n","print(\"✅ 已拷贝预处理数据 →\", PREPROC_DST)\n","\n","# 7. 准备 nnUNet_results：构建模型输出目录并放入 dataset.json、plans.json、checkpoint_final.pth\n","RES_DST   = Path(os.environ[\"nnUNet_results\"]) / DATASET\n","# 以下两个标识符请根据你训练时实际用的 trainer 和 plans 变化，\n","# 这里示例中脚本默认要找的是：nnUNetTrainer__nnUNetPlans__3d_fullres\n","TR_DIR    = RES_DST / \"nnUNetTrainer__nnUNetPlans__3d_fullres\"\n","FOLD0_DIR = TR_DIR  / \"fold_0\"\n","FOLD0_DIR.mkdir(parents=True, exist_ok=True)\n","\n","shutil.copy(DRIVE_ROOT/\"dataset.json\", TR_DIR/\"dataset.json\")\n","shutil.copy(DRIVE_ROOT/\"plans.json\",   TR_DIR/\"plans.json\")\n","shutil.copy(DRIVE_ROOT/\"checkpoint_final.pth\", FOLD0_DIR/\"checkpoint_final.pth\")\n","print(\"✅ 已拷贝模型权重 & 配置 →\", TR_DIR)\n","\n","# 8. 运行推理\n","device = \"cuda\" if Path(\"/usr/bin/nvidia-smi\").exists() else \"cpu\"\n","cmd = textwrap.dedent(f\"\"\"\n","    nnUNetv2_predict \\\n","      -i {RAW_TS} \\\n","      -o /content/pred \\\n","      -d {DATASET} \\\n","      -c 3d_fullres \\\n","      -f 0 \\\n","      -device {device} \\\n","      --disable_tta\n","\"\"\")\n","print(\"🚀 Running:\", cmd)\n","subprocess.run(cmd, shell=True, check=True)\n","print(\"✅ 推理完成 → /content/pred\")\n","\n","# 9. 复制预测结果回 Drive/output\n","OUT_DIR = DRIVE_ROOT / \"output\"\n","OUT_DIR.mkdir(exist_ok=True)\n","for p in Path(\"/content/pred\").glob(\"*.nii*\"):\n","    shutil.copy(p, OUT_DIR/p.name)\n","print(\"✅ 预测结果已复制到\", OUT_DIR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":526},"id":"8YpxNGkxR7C0","executionInfo":{"status":"error","timestamp":1747855147694,"user_tz":-480,"elapsed":85297,"user":{"displayName":"Silin","userId":"01581346555860269201"}},"outputId":"4afbded6-28aa-4806-fa7d-659cb4aee28d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ 已软链原始影像 → /content/nnUNet_raw/Dataset232_BraTS_2023_rGANs/imagesTs\n","✅ 已拷贝预处理数据 → /content/nnUNet_preprocessed/Dataset232_BraTS_2023_rGANs\n","✅ 已拷贝模型权重 & 配置 → /content/nnUNet_results/Dataset232_BraTS_2023_rGANs/nnUNetTrainer__nnUNetPlans__3d_fullres\n","🚀 Running: \n","nnUNetv2_predict       -i /content/nnUNet_raw/Dataset232_BraTS_2023_rGANs/imagesTs       -o /content/pred       -d Dataset232_BraTS_2023_rGANs       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n","\n"]},{"output_type":"error","ename":"CalledProcessError","evalue":"Command '\nnnUNetv2_predict       -i /content/nnUNet_raw/Dataset232_BraTS_2023_rGANs/imagesTs       -o /content/pred       -d Dataset232_BraTS_2023_rGANs       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n' returned non-zero exit status 1.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-daa42a7072e8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \"\"\")\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🚀 Running:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ 推理完成 → /content/pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCalledProcessError\u001b[0m: Command '\nnnUNetv2_predict       -i /content/nnUNet_raw/Dataset232_BraTS_2023_rGANs/imagesTs       -o /content/pred       -d Dataset232_BraTS_2023_rGANs       -c 3d_fullres       -f 0       -device cpu       --disable_tta\n' returned non-zero exit status 1."]}]},{"cell_type":"code","source":["completed = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n","print(completed.stdout)\n","print(completed.stderr)   # 真正的 traceback 在这里"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_MSW95DOZoe","executionInfo":{"status":"ok","timestamp":1747855252301,"user_tz":-480,"elapsed":9838,"user":{"displayName":"Silin","userId":"01581346555860269201"}},"outputId":"986de832-24d8-489d-cbf2-c7a868973744"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","perform_everything_on_device=True is only supported for cuda devices! Setting this to False\n","\n","/usr/local/lib/python3.11/dist-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n","/usr/local/lib/python3.11/dist-packages/nnunetv2/utilities/plans_handling/plans_handler.py:37: UserWarning: Detected old nnU-Net plans format. Attempting to reconstruct network architecture parameters. If this fails, rerun nnUNetv2_plan_experiment for your dataset. If you use a custom architecture, please downgrade nnU-Net to the version you implemented this or update your implementation + plans.\n","  warnings.warn(\"Detected old nnU-Net plans format. Attempting to reconstruct network architecture \"\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_predict\", line 8, in <module>\n","    sys.exit(predict_entry_point())\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/inference/predict_from_raw_data.py\", line 864, in predict_entry_point\n","    predictor.predict_from_files(args.i, args.o, save_probabilities=args.save_probabilities,\n","  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/inference/predict_from_raw_data.py\", line 244, in predict_from_files\n","    self._manage_input_and_output_lists(list_of_lists_or_source_folder,\n","  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/inference/predict_from_raw_data.py\", line 165, in _manage_input_and_output_lists\n","    list_of_lists_or_source_folder = create_lists_from_splitted_dataset_folder(list_of_lists_or_source_folder,\n","                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/utilities/utils.py\", line 42, in create_lists_from_splitted_dataset_folder\n","    identifiers = get_identifiers_from_splitted_dataset_folder(folder, file_ending)\n","                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/utilities/utils.py\", line 27, in get_identifiers_from_splitted_dataset_folder\n","    files = subfiles(folder, suffix=file_ending, join=False)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 71, in subfiles\n","    if entry.is_file() and \\\n","       ^^^^^^^^^^^^^^^\n","NotADirectoryError: [Errno 20] Not a directory: '/content/nnUNet_raw/Dataset232_BraTS_2023_rGANs/imagesTs/checkpoint_final.pth_0003.nii.gz'\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lewi7ZCRSnSU"},"execution_count":null,"outputs":[]}]}